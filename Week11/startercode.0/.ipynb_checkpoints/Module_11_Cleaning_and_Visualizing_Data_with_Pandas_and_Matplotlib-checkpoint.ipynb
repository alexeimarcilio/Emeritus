{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "# Module 11 - Cleaning and Visualizing Data with Pandas and Matplotlib\n",
    "\n",
    "\n",
    "**_Author: Jessica Cervi_**\n",
    "\n",
    "**Expected time = 3 hours**\n",
    "\n",
    "**Total points =  55 points**\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "## Assignment Overview\n",
    "\n",
    "In this assignment, we will use `pandas` to clean the data in a given dataframe. After performing some basic exploratory data analysis, we will make use of some `pandas` functions to profile and understand our data. Finally, we will convert some values in our dataframe in a more convenient format using the `.to_numeric()` function and we will filter our data to obtain a dataframe with only meaningful data.\n",
    "\n",
    "The last part of the assignment is designed as a learning experience for `folium`, a `gmap` alternative.\n",
    "\n",
    "\n",
    "This assignment is designed to build your familiarity and comfort coding in Python while also helping you review key topics from each module. As you progress through the assignment, answers will get increasingly complex. It is important that you adopt a data scientist's mindset when completing this assignment. **Remember to run your code from each cell before submitting your assignment.** Running your code beforehand will notify you of errors and give you a chance to fix your errors before submitting. You should view your Vocareum submission as if you are delivering a final project to your manager or client. \n",
    "\n",
    "***Vocareum Tips***\n",
    "- Do not add arguments or options to functions unless you are specifically asked to. This will cause an error in Vocareum.\n",
    "- Do not use a library unless you are expicitly asked to in the question. \n",
    "- You can download the Grading Report after submitting the assignment. This will include feedback and hints on incorrect questions. \n",
    "\n",
    "\n",
    "### Learning Objectives\n",
    "\n",
    "- Clean, filter, and group data with Pandas\n",
    "- Visualize data efficiently in Pandas\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "\n",
    "## Index: \n",
    "\n",
    "#### Module 11: Cleaning and Visualizing Data with Pandas and Matplotlib\n",
    "\n",
    "- [Question 1](#q1)\n",
    "- [Question 2](#q2)\n",
    "- [Question 3](#q3)\n",
    "- [Question 4](#q4)\n",
    "- [Question 5](#q5)\n",
    "- [Question 6](#q6)\n",
    "- [Question 7](#q7)\n",
    "- [Question 8](#q8)\n",
    "- [Question 9](#q9)\n",
    "- [Question 10](#q10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "## The Dataset\n",
    "\n",
    "\n",
    "For this assignment, we will be using a dataset similar to that in the lectures that provides a sample of the 311 calls in New York City .  This is a very large dataset, with mora e than 1,000,000 calls for 2019.  For this reason, we have selected a random sample of 2019's calls to make the dataset a bit more managable. The complete dataset can be explored [here](https://nycopendata.socrata.com/Social-Services/311-Service-Requests-from-2010-to-Present/erm2-nwe9).\n",
    "\n",
    "If you want to downoad the dataset separately, you will need to download the repository  by clicking on 'clone or download' and then clicking 'download as zip':\n",
    "\n",
    "<img src=\"./images/clone.png\" width=\"300px\">\n",
    "\n",
    "When the repository has been downloaded, do a search for `nyc_311_data_subset-2.csv` and place the file into a directory *data* where this Jupyter Notebook is saved.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "#### Reading in the Dataset\n",
    "\n",
    "As usual, we will begin by importing the necessary libraries and by reading the dataset into a dataframe called nyc_311 using the `pd.DataFrame.read_csv` method by using the following keyword arguments:\n",
    "\n",
    "- By specifying the index column to use, we are selecting a column from our source dataset to be used as our dataframe index instead of using the auto-generated `pandas.core.indexes.range.RangeIndex`. This helps us maintain a record of the rows of our source dataset, which can be a helpful reference if our dataset is changed (i.e. if someone else copies it and removes some rows and then overwrites it). If importing from a database export file, this is usually the primary key of the table.\n",
    "\n",
    "- When we import a csv file, pandas tries to guess what the type of each column is. In the case of `landmark`, `vehicle_type` and `incident_zip` fields, we have mixed types in some columns (i.e. strings, floats, and ints all in the same column) and pandas will throw a warning.  We can tell pandas what data type to expect with this argument, in this case `obect` for all three columns, to resolve this warning. We can attempt to convert the `incident_zip` datatype from string to integer with the `converters` keyword argument with a try/except block, but we'll be doing some string processing on that column later so we'll leave it as a string for our import.\n",
    "\n",
    "\n",
    "We will begin to clean and visualize data with `pandas`, after downloading and reading in the dataset. We will start by performing exploratory data analysis to understand and profile the missing values.\n",
    "\n",
    "\n",
    "**Note: Most of the questions in this assignment are connected and need to be solved in sequence.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline \n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "nyc_311 = pd.read_csv('data/nyc_311_data_subset-2.csv',index_col=0,dtype={'landmark': object,'vehicle_type': object,\n",
    "        'incident_zip': object})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>address_type</th>\n",
       "      <th>agency</th>\n",
       "      <th>agency_name</th>\n",
       "      <th>bbl</th>\n",
       "      <th>borough</th>\n",
       "      <th>bridge_highway_direction</th>\n",
       "      <th>bridge_highway_name</th>\n",
       "      <th>bridge_highway_segment</th>\n",
       "      <th>city</th>\n",
       "      <th>closed_date</th>\n",
       "      <th>...</th>\n",
       "      <th>resolution_description</th>\n",
       "      <th>road_ramp</th>\n",
       "      <th>status</th>\n",
       "      <th>street_name</th>\n",
       "      <th>taxi_company_borough</th>\n",
       "      <th>taxi_pick_up_location</th>\n",
       "      <th>unique_key</th>\n",
       "      <th>vehicle_type</th>\n",
       "      <th>x_coordinate_state_plane</th>\n",
       "      <th>y_coordinate_state_plane</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ADDRESS</td>\n",
       "      <td>NYPD</td>\n",
       "      <td>New York City Police Department</td>\n",
       "      <td>4.102260e+09</td>\n",
       "      <td>QUEENS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>JAMAICA</td>\n",
       "      <td>2019-01-06T13:06:59.000</td>\n",
       "      <td>...</td>\n",
       "      <td>The Police Department responded to the complai...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Closed</td>\n",
       "      <td>105 AVENUE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41352433</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1043267.0</td>\n",
       "      <td>194959.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ADDRESS</td>\n",
       "      <td>NYPD</td>\n",
       "      <td>New York City Police Department</td>\n",
       "      <td>4.100860e+09</td>\n",
       "      <td>QUEENS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>JAMAICA</td>\n",
       "      <td>2019-01-12T23:20:05.000</td>\n",
       "      <td>...</td>\n",
       "      <td>The Police Department responded to the complai...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Closed</td>\n",
       "      <td>WALTHAM STREET</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41407968</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1039186.0</td>\n",
       "      <td>191847.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ADDRESS</td>\n",
       "      <td>DFTA</td>\n",
       "      <td>Department for the Aging</td>\n",
       "      <td>4.066900e+09</td>\n",
       "      <td>QUEENS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FLUSHING</td>\n",
       "      <td>2019-02-21T09:37:06.000</td>\n",
       "      <td>...</td>\n",
       "      <td>The Department for the Aging contacted you and...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Closed</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41658034</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ADDRESS</td>\n",
       "      <td>NYPD</td>\n",
       "      <td>New York City Police Department</td>\n",
       "      <td>4.137450e+09</td>\n",
       "      <td>QUEENS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ROSEDALE</td>\n",
       "      <td>2019-05-05T02:20:18.000</td>\n",
       "      <td>...</td>\n",
       "      <td>The Police Department responded to the complai...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Closed</td>\n",
       "      <td>148 AVENUE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>42587192</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1055616.0</td>\n",
       "      <td>177905.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ADDRESS</td>\n",
       "      <td>DEP</td>\n",
       "      <td>Department of Environmental Protection</td>\n",
       "      <td>1.008398e+09</td>\n",
       "      <td>MANHATTAN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NEW YORK</td>\n",
       "      <td>2019-04-10T11:16:00.000</td>\n",
       "      <td>...</td>\n",
       "      <td>The Department of Environmental Protection det...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Closed</td>\n",
       "      <td>WEST   38 STREET</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>42180774</td>\n",
       "      <td>NaN</td>\n",
       "      <td>988485.0</td>\n",
       "      <td>213174.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  address_type agency                             agency_name           bbl  \\\n",
       "0      ADDRESS   NYPD         New York City Police Department  4.102260e+09   \n",
       "1      ADDRESS   NYPD         New York City Police Department  4.100860e+09   \n",
       "2      ADDRESS   DFTA                Department for the Aging  4.066900e+09   \n",
       "3      ADDRESS   NYPD         New York City Police Department  4.137450e+09   \n",
       "4      ADDRESS    DEP  Department of Environmental Protection  1.008398e+09   \n",
       "\n",
       "     borough bridge_highway_direction bridge_highway_name  \\\n",
       "0     QUEENS                      NaN                 NaN   \n",
       "1     QUEENS                      NaN                 NaN   \n",
       "2     QUEENS                      NaN                 NaN   \n",
       "3     QUEENS                      NaN                 NaN   \n",
       "4  MANHATTAN                      NaN                 NaN   \n",
       "\n",
       "  bridge_highway_segment      city              closed_date  ...  \\\n",
       "0                    NaN   JAMAICA  2019-01-06T13:06:59.000  ...   \n",
       "1                    NaN   JAMAICA  2019-01-12T23:20:05.000  ...   \n",
       "2                    NaN  FLUSHING  2019-02-21T09:37:06.000  ...   \n",
       "3                    NaN  ROSEDALE  2019-05-05T02:20:18.000  ...   \n",
       "4                    NaN  NEW YORK  2019-04-10T11:16:00.000  ...   \n",
       "\n",
       "                              resolution_description road_ramp  status  \\\n",
       "0  The Police Department responded to the complai...       NaN  Closed   \n",
       "1  The Police Department responded to the complai...       NaN  Closed   \n",
       "2  The Department for the Aging contacted you and...       NaN  Closed   \n",
       "3  The Police Department responded to the complai...       NaN  Closed   \n",
       "4  The Department of Environmental Protection det...       NaN  Closed   \n",
       "\n",
       "        street_name taxi_company_borough taxi_pick_up_location unique_key  \\\n",
       "0        105 AVENUE                  NaN                   NaN   41352433   \n",
       "1    WALTHAM STREET                  NaN                   NaN   41407968   \n",
       "2               NaN                  NaN                   NaN   41658034   \n",
       "3        148 AVENUE                  NaN                   NaN   42587192   \n",
       "4  WEST   38 STREET                  NaN                   NaN   42180774   \n",
       "\n",
       "  vehicle_type x_coordinate_state_plane y_coordinate_state_plane  \n",
       "0          NaN                1043267.0                 194959.0  \n",
       "1          NaN                1039186.0                 191847.0  \n",
       "2          NaN                      NaN                      NaN  \n",
       "3          NaN                1055616.0                 177905.0  \n",
       "4          NaN                 988485.0                 213174.0  \n",
       "\n",
       "[5 rows x 43 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nyc_311.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "[Back to top](#Index:) \n",
    "<a id='q1'></a>\n",
    "\n",
    "### Question 1:\n",
    "\n",
    "*5 points*\n",
    "    \n",
    "\n",
    "Use the `.info()` method to examine the number of non-null values in the bridge_highway_segment column.  Save your result as an integer to `ans1` below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 100000 entries, 0 to 99999\n",
      "Data columns (total 43 columns):\n",
      " #   Column                          Non-Null Count   Dtype  \n",
      "---  ------                          --------------   -----  \n",
      " 0   address_type                    97774 non-null   object \n",
      " 1   agency                          100000 non-null  object \n",
      " 2   agency_name                     100000 non-null  object \n",
      " 3   bbl                             82780 non-null   float64\n",
      " 4   borough                         100000 non-null  object \n",
      " 5   bridge_highway_direction        197 non-null     object \n",
      " 6   bridge_highway_name             197 non-null     object \n",
      " 7   bridge_highway_segment          251 non-null     object \n",
      " 8   city                            96353 non-null   object \n",
      " 9   closed_date                     95178 non-null   object \n",
      " 10  community_board                 100000 non-null  object \n",
      " 11  complaint_type                  100000 non-null  object \n",
      " 12  created_date                    100000 non-null  object \n",
      " 13  cross_street_1                  55253 non-null   object \n",
      " 14  cross_street_2                  55009 non-null   object \n",
      " 15  descriptor                      99100 non-null   object \n",
      " 16  due_date                        40619 non-null   object \n",
      " 17  facility_type                   30055 non-null   object \n",
      " 18  incident_address                86334 non-null   object \n",
      " 19  incident_zip                    96324 non-null   object \n",
      " 20  index                           100000 non-null  int64  \n",
      " 21  intersection_street_1           10598 non-null   object \n",
      " 22  intersection_street_2           10532 non-null   object \n",
      " 23  landmark                        24 non-null      object \n",
      " 24  latitude                        93983 non-null   float64\n",
      " 25  level_0                         100000 non-null  int64  \n",
      " 26  location                        93983 non-null   object \n",
      " 27  location_type                   78903 non-null   object \n",
      " 28  longitude                       93983 non-null   float64\n",
      " 29  open_data_channel_type          100000 non-null  object \n",
      " 30  park_borough                    100000 non-null  object \n",
      " 31  park_facility_name              100000 non-null  object \n",
      " 32  resolution_action_updated_date  98220 non-null   object \n",
      " 33  resolution_description          92168 non-null   object \n",
      " 34  road_ramp                       197 non-null     object \n",
      " 35  status                          100000 non-null  object \n",
      " 36  street_name                     86330 non-null   object \n",
      " 37  taxi_company_borough            71 non-null      object \n",
      " 38  taxi_pick_up_location           319 non-null     object \n",
      " 39  unique_key                      100000 non-null  int64  \n",
      " 40  vehicle_type                    5 non-null       object \n",
      " 41  x_coordinate_state_plane        93983 non-null   float64\n",
      " 42  y_coordinate_state_plane        93983 non-null   float64\n",
      "dtypes: float64(5), int64(3), object(35)\n",
      "memory usage: 33.6+ MB\n"
     ]
    }
   ],
   "source": [
    "### GRADED\n",
    "\n",
    "### YOUR SOLUTION HERE\n",
    "ans1 = nyc_311.info()\n",
    "\n",
    "###\n",
    "### YOUR CODE HERE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "Question 01",
     "locked": true,
     "points": "5",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "[Back to top](#Index:) \n",
    "<a id='q2'></a>\n",
    "\n",
    "### Question 2:\n",
    "\n",
    "*5 points*\n",
    "    \n",
    "\n",
    "Recall that the `.isnull()` method returns boolean values as to whether or not a value is null.  We can find the total number of null values by summing the values returned by the `.isnull()` method.\n",
    "\n",
    "\n",
    "Use the `.isnull()` method together with the `.sum()` method to return a series of null counts for each column.\n",
    "Turn these values into a percentage and save your series to `ans2` below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### GRADED\n",
    "\n",
    "### YOUR SOLUTION HERE\n",
    "ans2 = None\n",
    "\n",
    "###\n",
    "### YOUR CODE HERE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "Question 02",
     "locked": true,
     "points": "5",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "[Back to top](#Index:) \n",
    "<a id='q3'></a>\n",
    "\n",
    "### Question 3:\n",
    "\n",
    "*10 points*\n",
    "    \n",
    "\n",
    "**Data profiling** is the process of examining the data available from an existing [information source](https://en.wikipedia.org/wiki/Data_profiling).\n",
    "\n",
    "We recognize that we have missing values in the previous problem  and want to write a function that takes in a `dataframe` and returns a `series` of only those columns with more than x% of their data missing (defaulting to 50%, or 0.5 as a float). The values in the returned `series` object will be a float value representing the percent missing data for the corresponding index.\n",
    "\n",
    "\n",
    "Define a function `mostly_missing` that takes, as input, a dataframe and a float `level = 0.5`. This function\n",
    "returns a series with the values for the features missing a larger percentage than the threshold value.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### GRADED\n",
    "\n",
    "### YOUR SOLUTION HERE\n",
    "def mostly_missing(df, level = 0.5):\n",
    "    '''\n",
    "    This function accepts a DataFrame\n",
    "    and returns a series with the values\n",
    "    for the features missing a larger percentage\n",
    "    than the threshold value.\n",
    "    \n",
    "    -------------------\n",
    "    Check:\n",
    "    mostly_missing(nyc_311)\n",
    "    \n",
    "    returns ===>>>\n",
    "    \n",
    "    bridge_highway_direction    0.99803\n",
    "    bridge_highway_name         0.99803\n",
    "    bridge_highway_segment      0.99749\n",
    "    due_date                    0.59381\n",
    "    intersection_street_1       0.89402\n",
    "    intersection_street_2       0.89468\n",
    "    landmark                    0.99976\n",
    "    road_ramp                   0.99803\n",
    "    taxi_company_borough        0.99929\n",
    "    taxi_pick_up_location       0.99681\n",
    "    vehicle_type                0.99995\n",
    "    '''\n",
    "    return\n",
    "\n",
    "###\n",
    "### YOUR CODE HERE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "Question 03",
     "locked": true,
     "points": "10",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "[Back to top](#Index:) \n",
    "<a id='q4'></a>\n",
    "\n",
    "### Question 4:\n",
    "\n",
    "*10 points*\n",
    "    \n",
    "In addition to deciding how to handle our missing data we must work with `datetime` objects to ensure they are useful for analysis.  To avoid repeating operations, we will write a function to test whether a column name contains the word `date` and then attempt the `datetime` conversion on those column(s). When completed, the original dataframe is returned with any `date` containing columns in their datetime converted forms.\n",
    "\n",
    "*Note*: Explore the Pandas file reader methods such as the `.read_csv()` method.  There is a default datetime conversion argument that sometimes is an easier approach.\n",
    "\n",
    "Define a function `date_timer` that takes, as input, a dataframe. Your function should look for any column containing the word \"date\". It should change the data in these columns to floats using the function `.datetime()` and return the updated dataframe `df_copy`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### GRADED\n",
    "\n",
    "### YOUR SOLUTION HERE\n",
    "def date_timer(df):\n",
    "    '''\n",
    "    This function takes in a DataFrame\n",
    "    and looks for any column containing the word \"date\".\n",
    "    These columns are changed to datetime datatypes where possible,\n",
    "    and the new updated dataframe is returned.\n",
    "    \n",
    "    **HINT**\n",
    "    Your new dataframe should contain four features that\n",
    "    are datetime datatypes.\n",
    "    '''\n",
    "    return\n",
    "\n",
    "###\n",
    "### YOUR CODE HERE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "Question 04",
     "locked": true,
     "points": "5",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "[Back to top](#Index:) \n",
    "<a id='q5'></a>\n",
    "\n",
    "### Question 5:\n",
    "\n",
    "*5 points*\n",
    "    \n",
    "Now that we have columns in `datetime` format, we can create a new column named `processing_time`.  To do so, we will take the difference between the `closed_date` and `created_date` columns.\n",
    "\n",
    "Create a new column `time_to_close`  that has, as entries, the difference between closed_date and created_date in `df_copy`.  Save your new dataframe including the new column to `ans5` below.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### GRADED\n",
    "\n",
    "### YOUR SOLUTION HERE\n",
    "\n",
    "df_copy['processing_time'] = None\n",
    "\n",
    "###\n",
    "### YOUR CODE HERE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "Question 05",
     "locked": true,
     "points": "5",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to top](#Index:) \n",
    "<a id='q6'></a>\n",
    "\n",
    "### Question 6:\n",
    "\n",
    "*5 points*\n",
    "    \n",
    "Now that we have our new `time_to_close` column, we can explore it using the `.nlargest()` method, to examine the 10 longest closing times from the 2019 311 sample. \n",
    "\n",
    "\n",
    "Use your dataframe with the `time_to_close` column and the `.nlargest()` method to select the 10 longest closing times in our data from `df_copy`. Save your results as a dataframe to `ans6` below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### GRADED\n",
    "\n",
    "### YOUR SOLUTION HERE\n",
    "\n",
    "ans6 = None\n",
    "\n",
    "###\n",
    "### YOUR CODE HERE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "Question 06",
     "locked": true,
     "points": "5",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to top](#Index:) \n",
    "<a id='q7'></a>\n",
    "\n",
    "### Question 7:\n",
    "\n",
    "*5 points*\n",
    "    \n",
    "The `.groupby()` method works on a categorical column to group like values.  Once grouped, we will apply a function to each of these groups.  For example,\n",
    "\n",
    "```python\n",
    "nyc_311.groupby('agency_name').size().sort_values(ascending = False)\n",
    "```\n",
    "returns a series of counts of observations within each agency.  \n",
    "\n",
    "Use the code example above to determine the top 5  agency names from our dataset `df_copy`.  Save your results as a series to `ans7` below. Sort the values in descending order.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### GRADED\n",
    "\n",
    "### YOUR SOLUTION HERE\n",
    "\n",
    "ans7 = None\n",
    "\n",
    "###\n",
    "### YOUR CODE HERE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "Question 07",
     "locked": true,
     "points": "5",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "[Back to top](#Index:) \n",
    "<a id='q8'></a>\n",
    "\n",
    "### Question 8:\n",
    "\n",
    "*5 points*\n",
    "    \n",
    "When we group by multiple features, we are returned a multi-index series.  To get back to a familiar `dataframe` object, we use the `.unstack()` method.  For example:\n",
    "\n",
    "```python\n",
    "agency_borough = nyc_311.groupby(['agency', 'borough']).size().unstack()\n",
    "```\n",
    "\n",
    "This will first group our data by `agency`, and then by `borough` in `df_copy`, counting the number of occurrences for each agency. Use the code above and examine the output. Use the `.loc()` method to locate the  number of DOE incidents in QUEENS. Save your solution to `ans8` as a float."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### GRADED\n",
    "\n",
    "### YOUR SOLUTION HERE\n",
    "\n",
    "ans8 = None\n",
    "\n",
    "###\n",
    "### YOUR CODE HERE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "Question 08",
     "locked": true,
     "points": "5",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "[Back to top](#Index:) \n",
    "<a id='q9'></a>\n",
    "\n",
    "### Question 9:\n",
    "\n",
    "*5 points*\n",
    "    \n",
    "\n",
    "As with the lecture, we have certain problems with our `zipcode` column.  The function below is from the lecture and demonstrates an approach to cleaning our zipcodes.  \n",
    "\n",
    "```python\n",
    "def fix_zip(input_zip):\n",
    "    try:\n",
    "        input_zip = int(float(input_zip))\n",
    "    except:\n",
    "        try:\n",
    "            input_zip = int(input_zip.split('-')[0])\n",
    "        except:\n",
    "            return np.NaN\n",
    "    if input_zip < 10000 or input_zip > 19999:\n",
    "        return np.NaN\n",
    "    return str(input_zip)\n",
    "```\n",
    "\n",
    "\n",
    "Use the function fix_zip above to clean the `incident_zip` column in `df_copy`. Use the `.apply()` method to clean the feature and save your cleaned series to `ans9` below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### GRADED\n",
    "\n",
    "### YOUR SOLUTION HERE\n",
    "\n",
    "ans9 = None \n",
    "\n",
    "###\n",
    "### YOUR CODE HERE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "Question 09",
     "locked": true,
     "points": "5",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "[Back to top](#Index:) \n",
    "<a id='q10'></a>\n",
    "\n",
    "### Question 10:\n",
    "\n",
    "*10 points*\n",
    "    \n",
    "Now that we have cleaned up the zip codes, let's drop any remaining null values.\n",
    "\n",
    "Create a dataframe that has only zip codes in `df_copy` that are non-null.  Save the dataframe to `ans10` below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### GRADED\n",
    "\n",
    "### YOUR SOLUTION HERE\n",
    "\n",
    "ans10 = None\n",
    "\n",
    "###\n",
    "### YOUR CODE HERE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "Question 10",
     "locked": true,
     "points": "10",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "## Part II: Mapping with `folium`\n",
    "\n",
    "As we saw in the lectures,  `gmaps` is a powerful plugin for embedding Google maps in Jupyter notebooks. \n",
    "Normally, to use `gmaps`, you would need to get an API key which prevents us from immediately making maps here.  Instead, we will use another library called `folium`. If you do not have `folium` installed, you can install it from within your notebook by typing:\n",
    "\n",
    "```python\n",
    "!pip install folium\n",
    "```\n",
    "and executing the cell.\n",
    "\n",
    "- **NOTE:** The following questions are not graded.\n",
    "- You can apply the techniques below to any data with latitude and longitude!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "#### A Basic Map\n",
    "\n",
    "We will create a basic map centered at the first latitude longitude pair in the dataset.  This is just a demonstration and meant just for exploration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "import folium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "nyc_311[['latitude', 'longitude']]  = nyc_311[['latitude', 'longitude']].astype('float')\n",
    "start = nyc_311.loc[0, ['latitude', 'longitude']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "m = folium.Map(location = (start[0], start[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "#### Adding a Marker\n",
    "\n",
    "We can add a marker at the first location using the `.Marker` method.  Here, we provide the location and add the marker to our map `m` with the `.add_to()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "folium.Marker(location=(start[0], start[1]),\n",
    "                 popup = nyc_311['complaint_type'][0]).add_to(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choropleth Map\n",
    "\n",
    "Many municipalities make GeoJson files available with information about district boundaries of all kinds.  Below, we use the zip code data from New York City to draw in boundaries by zip codes.  Then, we can bind our data to the map using the zip codes that are housed in the `.json` files. The main idea here is that we will count incidents by zip code and color the map based on this.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#creating a new DataFrame of complaints by zipcodes\n",
    "complaints = nyc_311.groupby('incident_zip')[['complaint_type']].size().to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#renaming the size column\n",
    "complaints.columns = ['num']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#create a zipcode column\n",
    "#based on the index\n",
    "complaints['zip'] = complaints.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "complaints.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#create boundaries for values\n",
    "#to be colored on\n",
    "vals = complaints.quantile([.1, .3, .5, .7, .9])['num'] \n",
    "vals = list(vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vals.append(complaints.num.max() + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "#url to import the geojson data from nyc\n",
    "url = 'http://data.beta.nyc//dataset/3bf5fb73-edb5-4b05-bb29-7c95f4a727fc/resource/6df127b1-6d04-4bb7-b983-07402a2c3f90/download/f4129d9aa6dd4281bc98d0f701629b76nyczipcodetabulationareas.geojson'\n",
    "#create a dictionary like object from geojson \n",
    "geo_json_data = json.loads(requests.get(url).text)\n",
    "#create our map\n",
    "m = folium.Map([start[0], start[1]], zoom_start=9.5, tiles = 'Stamen Toner')\n",
    "#add the boundaries and colors\n",
    "m.choropleth(geo_json_data, data = complaints, columns = ['zip','num'], \n",
    "             #this is the key from json dictionary\n",
    "             key_on = 'feature.properties.postalCode', \n",
    "             threshold_scale= vals, \n",
    "             #these are RColorBrewer codes\n",
    "             fill_color= 'BuPu')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
