{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "# Module 21 - Text Mining in Python - Topic Modeling\n",
    "\n",
    "\n",
    "**_Author: Jessica Cervi_**\n",
    "\n",
    "**Expected time = 3 hours**\n",
    "\n",
    "**Total points = 120 points**\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "\n",
    "    \n",
    "\n",
    "    \n",
    "## Assignment Overview\n",
    "\n",
    "In this assignment, we will continue working with Text Mining to explore a few examples similar to those in the lectures from this week. First, we will review how to tokenize, tag, and chunk some text in Python. Next, we will use named entities and sentiment analysis to extract sentiment in news articles for given entities. Finally, we will use text summarization techniques to shorten long pieces of text.\n",
    "\n",
    "\n",
    "This assignment is designed to build your familiarity and comfort coding in Python while also helping you review key topics from each module. As you progress through the assignment, answers will get increasingly complex. It is important that you adopt a data scientist's mindset when completing this assignment. **Remember to run your code from each cell before submitting your assignment.** Running your code beforehand will notify you of errors and give you a chance to fix your errors before submitting. You should view your Vocareum submission as if you are delivering a final project to your manager or client. \n",
    "\n",
    "***Vocareum Tips***\n",
    "- Do not add arguments or options to functions unless you are specifically asked to. This will cause an error in Vocareum.\n",
    "- Do not use a library unless you are expicitly asked to in the question. \n",
    "- You can download the Grading Report after submitting the assignment. This will include feedback and hints on incorrect questions. \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### Learning Objectives\n",
    "\n",
    "- Summarize texts and isolate topics in sample data \n",
    "- Perform named entity analysis using Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "\n",
    "## Index:\n",
    "\n",
    "#### Module 21: Text Mining in Python\n",
    "\n",
    "- [Question 1](#q1)\n",
    "- [Question 2](#q2)\n",
    "- [Question 3](#q3)\n",
    "- [Question 4](#q4)\n",
    "- [Question 5](#q5)\n",
    "- [Question 6](#q6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "## Module 21: Text Mining in Python - Topic Modeling\n",
    "\n",
    "\n",
    "\n",
    "In the first part of this assignment, we will be testing your knowledge of the topics covered in Module 12, such as tokenizing, tag, and chunk our data \n",
    "\n",
    "\n",
    "We will use a dataset of articles gathered from the New York Times API relating to elections.  \n",
    "\n",
    "Before proceeding, ensure that you have the following packages installed on your machine:\n",
    "- [nltk](https://www.nltk.org)- The leading platform for building Python programs to work with human language data.\n",
    "\n",
    "- [gensim](https://pypi.org/project/gensim/) - An open-source library for unsupervised topic modeling and natural language processing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "### Reading the dataset and tokenizing data\n",
    "\n",
    "We will begin this assignment by reading the dataset in a DataFrame `df` and by performing some data claning. Next, you will be asked to tokenize your data. Remember, tokenization  is the process by which big quantity of text is divided into smaller parts called tokens.\n",
    "\n",
    "As usual, we begin by importing the `pandas` library and by reading the dataset into a DataFrame `df`. Next, because it won't be useful in out analysis, we drop the advertisements section and convert the values stored in the column `date` to floats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('data/nyt_headlines.csv')\n",
    "df.drop(index=df[df['section'] == 'Briefing'].index, inplace=True)\n",
    "df['date'] = pd.to_datetime(df['date'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "Finally, we visualize the first five rown of `df` and extract some information using the function `.info()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>section</th>\n",
       "      <th>lead_paragraph</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-07-25 21:48:55+00:00</td>\n",
       "      <td>U.S.</td>\n",
       "      <td>WASHINGTON — The Senate Intelligence Committee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-08-30 11:15:22+00:00</td>\n",
       "      <td>World</td>\n",
       "      <td>JERUSALEM — The leader of the main Arab factio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-08-29 18:00:28+00:00</td>\n",
       "      <td>U.S.</td>\n",
       "      <td>BEAVER DAM, Wis. — Democratic Wisconsin Gov. T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-08-29 16:57:23+00:00</td>\n",
       "      <td>World</td>\n",
       "      <td>JERUSALEM — A small Israeli ultranationalist p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-05-06 12:37:46+00:00</td>\n",
       "      <td>World</td>\n",
       "      <td>NEW DELHI — Violence disrupted the Indian elec...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       date section  \\\n",
       "0 2019-07-25 21:48:55+00:00    U.S.   \n",
       "1 2019-08-30 11:15:22+00:00   World   \n",
       "2 2019-08-29 18:00:28+00:00    U.S.   \n",
       "3 2019-08-29 16:57:23+00:00   World   \n",
       "4 2019-05-06 12:37:46+00:00   World   \n",
       "\n",
       "                                      lead_paragraph  \n",
       "0  WASHINGTON — The Senate Intelligence Committee...  \n",
       "1  JERUSALEM — The leader of the main Arab factio...  \n",
       "2  BEAVER DAM, Wis. — Democratic Wisconsin Gov. T...  \n",
       "3  JERUSALEM — A small Israeli ultranationalist p...  \n",
       "4  NEW DELHI — Violence disrupted the Indian elec...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 932 entries, 0 to 963\n",
      "Data columns (total 3 columns):\n",
      " #   Column          Non-Null Count  Dtype              \n",
      "---  ------          --------------  -----              \n",
      " 0   date            932 non-null    datetime64[ns, UTC]\n",
      " 1   section         932 non-null    object             \n",
      " 2   lead_paragraph  932 non-null    object             \n",
      "dtypes: datetime64[ns, UTC](1), object(2)\n",
      "memory usage: 29.1+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "Next, we import  the function the function `.sent_tokenize()` from the library `NLTK`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "from nltk import sent_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "[Back to top](#Index:) \n",
    "<a id='q1'></a>\n",
    "\n",
    "### Question 1:\n",
    "\n",
    "*20 points*\n",
    "\n",
    "Create a list of sentences (tokenizing) the data from  the `lead_paragraph` series. To do so, define function `make_sents` which takes a `pandas` `Series`as an argument. Your function should use the function ``sent_tokenize`` to return a *nested list* with all sentences from the input `Series` collapsed into a single list.\n",
    "        \n",
    "Consider the example below:\n",
    "\n",
    "|Sample Series Input|\n",
    "| --- |\n",
    "|\"The cat. In the hat.\"|\n",
    "|\"One fish. Two fish. Red fish.\"|\n",
    "\n",
    "Output:\n",
    "`[['The cat.', 'In the hat.'], ['One fish.', 'Two fish.', 'Red fish.']]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### GRADED\n",
    "\n",
    "### YOUR SOLUTION HERE\n",
    "def make_sents(s):\n",
    "    return\n",
    "\n",
    "###\n",
    "### YOUR CODE HERE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "Question 01",
     "locked": true,
     "points": "10",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "### Tag and chunk the Data\n",
    "\n",
    "Extracting the named entities using the library `NLTK` requires tagging each word with a part of speech using the function `.pos_tag()` and passing these to the `ne_chunk` method.  From here, we can obtain a tree representation of the sentence that includes any relevant named entity tags.  A full list of the entity tags can be found [here](https://pythonprogramming.net/part-of-speech-tagging-nltk-tutorial/).\n",
    "\n",
    "Below, import the necessary libraries to we examine a simple example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "from nltk import word_tokenize, pos_tag, ne_chunk\n",
    "sample_sent = 'Today Google won the election.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "w = word_tokenize(sample_sent)\n",
    "pos = pos_tag(w)\n",
    "ne = ne_chunk(pos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "[Back to top](#Index:) \n",
    "<a id='q2'></a>\n",
    "### Question 2:\n",
    "\n",
    "*20 points*\n",
    "\n",
    "Define a function, `make_chunks` that accepts, as input, a function which generates a list of  structured set of texts (corpora). Default the input of the function to `make_sents`. Your function should:\n",
    "\n",
    "- Iterate through the list of corpora and assign a dictionary integer key, starting at 0 (this is the _row_ key).\n",
    "- Iterates through the sentences of corpora and assign a dictionary integer key, starting at 0 (this is the _sentence_ key).\n",
    "\n",
    "Your function should return the dictonary defined in the previous iterations.\n",
    "\n",
    "**Hint: use the functions `word_tokenize`, `pos_tag`, `ne_chunk` and two nested `for` loops**\n",
    "    \n",
    "Consider the example below (before chunking):\n",
    "\n",
    "```python\n",
    "df['lead_paragraph'][6]\n",
    "```\n",
    "Output:\n",
    "```\n",
    "'ATHENS — Four years ago almost to this day, Greece came a breath away from leaving the euro. People formed quiet, somber lines outside banks to take out small amounts of cash, as a lockdown on the financial system barred them from accessing their savings. They stockpiled tinned food and toilet paper.'\n",
    "```\n",
    "\n",
    "The same text, after chunking, should be:\n",
    "\n",
    "```python\n",
    "print(make_chunks(ms=make_sents)[6])\n",
    "```\n",
    "Output:\n",
    "```\n",
    "{0: [Tree('GPE', [('ATHENS', 'NNP')]), ('—', 'NNP'), ('Four', 'CD'), ('years', 'NNS'), ('ago', 'RB'), ('almost', 'RB'), ('to', 'TO'), ('this', 'DT'), ('day', 'NN'), (',', ','), Tree('GPE', [('Greece', 'NNP')]), ('came', 'VBD'), ('a', 'DT'), ('breath', 'NN'), ('away', 'RB'), ('from', 'IN'), ('leaving', 'VBG'), ('the', 'DT'), ('euro', 'NN'), ('.', '.')], 1: [('People', 'NNS'), ('formed', 'VBD'), ('quiet', 'JJ'), (',', ','), ('somber', 'JJ'), ('lines', 'NNS'), ('outside', 'JJ'), ('banks', 'NNS'), ('to', 'TO'), ('take', 'VB'), ('out', 'RP'), ('small', 'JJ'), ('amounts', 'NNS'), ('of', 'IN'), ('cash', 'NN'), (',', ','), ('as', 'IN'), ('a', 'DT'), ('lockdown', 'NN'), ('on', 'IN'), ('the', 'DT'), ('financial', 'JJ'), ('system', 'NN'), ('barred', 'VBD'), ('them', 'PRP'), ('from', 'IN'), ('accessing', 'VBG'), ('their', 'PRP$'), ('savings', 'NNS'), ('.', '.')], 2: [('They', 'PRP'), ('stockpiled', 'VBD'), ('tinned', 'VBN'), ('food', 'NN'), ('and', 'CC'), ('toilet', 'NN'), ('paper', 'NN'), ('.', '.')]}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### GRADED\n",
    "\n",
    "### YOUR SOLUTION HERE\n",
    "def make_chunks(s):\n",
    "    return\n",
    "\n",
    "###\n",
    "### YOUR CODE HERE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "Question 02",
     "locked": true,
     "points": "10",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "Finally, we will use the tree representation to generate a dictionary of named entities.  We do this by examining each tree based on whether or not a named entity label has been provided.  \n",
    "\n",
    "Below, we reconsider the simple example given above: note that only the word `Google` is identified as a named entity.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "#Test sentence\n",
    "sample_sent = 'Today Google won the election.'\n",
    "#Tokenize, tag and chunk\n",
    "w = word_tokenize(sample_sent)\n",
    "pos = pos_tag(w)\n",
    "ne = ne_chunk(pos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we examine the output with visual representations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "ne.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ne[1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "ne[1].label()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "ne[1].leaves()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "[Back to top](#Index:) \n",
    "<a id='q3'></a>\n",
    "\n",
    "### Question 3:\n",
    "\n",
    "*20 points*\n",
    "\n",
    "Define a function `get_pos` which takes as input a function which returns a chunked dictionary.  Default the input of the function to `make_sents`. Your function should return a dictionary where:\n",
    "- The key is the integer value of the source dataset row and  value is a _list_ of _dictionaries_ where:\n",
    "- The key is a string value of the named entity and the value is a tuple where:\n",
    "- The first element is the entity tag and the second element is the part of speech tag\n",
    "\n",
    "Obberve the example below:\n",
    "\n",
    "```python\n",
    "get_pos(mc=make_chunks)[6]\n",
    "```\n",
    "\n",
    "Returns:\n",
    "```\n",
    "[{'ATHENS': ('GPE', 'NNP')}, {'Greece': ('GPE', 'NNP')}]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### GRADED\n",
    "\n",
    "### YOUR SOLUTION HERE\n",
    "def get_pos(s):\n",
    "    return\n",
    "\n",
    "###\n",
    "### YOUR CODE HERE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "Question 03",
     "locked": true,
     "points": "10",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "### Sentiment of an Entity\n",
    "In this part of the assignment we use Vader to investigate the sentiment of headlines containing a specific entity. Remember, sentiment analysis is the process of *computationally* determining whether a piece of writing is positive, negative or neutral.\n",
    "\n",
    "For this part we import the following necessary function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "[Back to top](#Index:) \n",
    "<a id='q4'></a>\n",
    "\n",
    "### Question 4\n",
    "\n",
    "*20 points*\n",
    "\n",
    "Define a function `get_sentiment_df` that takes, as input a required case-insensitive string search word (default this to the word `Putin`), and sentence list generator function. Default this second input to `make_sents`. \n",
    "\n",
    "Your function should searches through the resultant list of sentences output from `make_sents` for the input search word and return a DataFrame with three columns:\n",
    "\n",
    " - `lead_paragraph_index`: the originating row number (parent index) of the sentence list\n",
    " - `sentence`: the string sentence to which sentiment is evaluated against\n",
    " - `compound_sentiment`: the float value which is the compound sentiment returned by  the function`.polarity_scores()`\n",
    " \n",
    " *Hint:* It is possible to have multiple rows on the output per index, as each parent row may contain multiple sentences\n",
    "\n",
    "Consider the example below:\n",
    "\n",
    "```python\n",
    "get_sentiment_df('Putin', ms=make_sents)\n",
    "```\n",
    "\n",
    "Example Output:\n",
    "<table border=\"1\" class=\"dataframe\">  <thead>    <tr style=\"text-align: right;\">      <th></th>      <th>lead_paragraph_index</th>      <th>sentence</th>      <th>compound_sentiment</th>    </tr>  </thead>  <tbody>    <tr>      <th>0</th>      <td>150</td>      <td>President Trump and President Vladimir V. Puti...</td>      <td>0.0000</td>    </tr>    <tr>      <th>1</th>      <td>219</td>      <td>And then President Trump brushed off Russia’s ...</td>      <td>0.5267</td>    </tr>    <tr>      <th>2</th>      <td>768</td>      <td>A day after President Trump’s remarks alongsid...</td>      <td>-0.1027</td>    </tr>    <tr>      <th>3</th>      <td>772</td>      <td>During a news conference with President Vladim...</td>      <td>0.0000</td>    </tr>    <tr>      <th>4</th>      <td>775</td>      <td>A day after President Trump’s remarks alongsid...</td>      <td>-0.1027</td>    </tr>    <tr>      <th>5</th>      <td>795</td>      <td>RUSSIAN ROULETTE The Inside Story of Putin’s W...</td>      <td>-0.5994</td>    </tr>    <tr>      <th>6</th>      <td>805</td>      <td>SARAJEVO, Bosnia and Herzegovina — Just before...</td>      <td>0.4576</td>    </tr>    <tr>      <th>7</th>      <td>826</td>      <td>WASHINGTON — Russians working for a close ally...</td>      <td>0.0772</td>    </tr>    <tr>      <th>8</th>      <td>845</td>      <td>On an October afternoon before the 2016 electi...</td>      <td>0.3182</td>    </tr>    <tr>      <th>9</th>      <td>871</td>      <td>Maria Butina, a Russian woman who tried to bro...</td>      <td>0.2500</td>    </tr>    <tr>      <th>10</th>      <td>871</td>      <td>During a news conference in Helsinki, Finland,...</td>      <td>0.4767</td>    </tr>    <tr>      <th>11</th>      <td>871</td>      <td>Here are three books that provide insight into...</td>      <td>0.4767</td>    </tr>    <tr>      <th>12</th>      <td>915</td>      <td>HELSINKI, Finland — President Trump stood next...</td>      <td>0.2023</td>    </tr>    <tr>      <th>13</th>      <td>930</td>      <td>President Vladimir Putin’s real challenge in S...</td>      <td>-0.1872</td>    </tr>    <tr>      <th>14</th>      <td>932</td>      <td>WASHINGTON — In 2016, American intelligence ag...</td>      <td>0.6808</td>    </tr>  </tbody></table>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### GRADED\n",
    "\n",
    "### YOUR SOLUTION HERE\n",
    "def get_sentiment_df(sw, ms):\n",
    "    return\n",
    "\n",
    "###\n",
    "### YOUR CODE HERE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "Question 04",
     "locked": true,
     "points": "10",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "### Summarization \n",
    "\n",
    "Now, we turn to the problem of text summarization. Remember, text summarization refers to the technique of shortening long pieces of text with the intention  to create a coherent and fluent summary having only the main points outlined in the document.\n",
    "\n",
    "We will use the example using the `gensim.summarization` module.  Our goal will be to build on our example where  we extracted meaningful sentences and provide a summary of the headlines related to a given entity. Below, we demonstrate an example of  the `gensim.summarization.summarize` method on our existing meaningful sentences.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "import gensim.summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "gensim.summarization.summarize_corpus(make_sents())[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "[Back to top](#Index:) \n",
    "<a id='q5'></a>\n",
    "\n",
    "### Question 5: \n",
    "\n",
    "*20 points*\n",
    "\n",
    "Write a function `get_summary` which takes as input a case-insensitive, string search word (default to `Putin`) and the DataFrame `df` defined in Question 4. Your function should return a list of lists showing all articles summarizing the string search word returned by `summarize_corpus()` \n",
    "\n",
    "Consider the example below :\n",
    "\n",
    "```python\n",
    "get_summary('Putin', df=df)\n",
    "```\n",
    "\n",
    "Example Output:\n",
    "```\n",
    "[['During a news conference with President Vladimir V. Putin of Russia, President Trump would not say whether he believed Russia meddled with the 2016 presidential election.'],\n",
    " ['RUSSIAN ROULETTE The Inside Story of Putin’s War on America and the Election of Donald Trump By Michael Isikoff and David Corn 338 pp. Twelve. $30.']]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### GRADED\n",
    "\n",
    "### YOUR SOLUTION HERE\n",
    "def get_summary(sw, df):\n",
    "    return\n",
    "\n",
    "###\n",
    "### YOUR CODE HERE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "Question 05",
     "locked": true,
     "points": "10",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "### Topic Modeling\n",
    "\n",
    "In this part of the assignment we demonstrate the use of the library `sklearn` topic modeling  capabilities.  Here, we rely on the `LatentDirichletAllocation` class that implements the LDA algorithm as demonstrated in the lectured.  This class expects a  vectorized array, accomplished  with the `CountVectorizer` or `TfidfVectorizer`.\n",
    "\n",
    "As usual, we begin by importing the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import NMF, LatentDirichletAllocation\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "#instantiate LDA and CountVectorizer class\n",
    "lda = LatentDirichletAllocation()\n",
    "cvect = CountVectorizer(stop_words='english')\n",
    "\n",
    "#Transform lead_paragraph into document term matrix\n",
    "dtm = cvect.fit_transform(df['lead_paragraph'])\n",
    "\n",
    "#generate list of topics\n",
    "topics = lda.fit_transform(dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "#function to print top words in each topic\n",
    "def print_top_words(model, feature_names, n_top_words):\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        message = \"Topic #%d: \" % topic_idx\n",
    "        message += \" \".join([feature_names[i]\n",
    "                             for i in topic.argsort()[:-n_top_words - 1:-1]])\n",
    "        print(message)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "#create feature names variable and use in print_top_words function below.\n",
    "feature_names = cvect.get_feature_names()\n",
    "print_top_words(lda, feature_names, n_top_words=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "From here, we are able to identify the probability of a given topic use the fit instance  of `LatentDirichletAlocation`.  We feed the fit instance a sample text and are returned an array of probabilities for topic relation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "#sample headline to determine topic probability with\n",
    "sample_headline = df['lead_paragraph'][12]\n",
    "print(sample_headline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "#transform and view probabilities for topics\n",
    "import numpy as np\n",
    "samp_cvect = cvect.transform(np.array([sample_headline]))\n",
    "lda.transform(samp_cvect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "#sort top tokens in topic with highest probability\n",
    "feats = cvect.get_feature_names()\n",
    "topics = lda.components_[4]\n",
    "pd.DataFrame({'prob': topics, 'features': feats}).nlargest(10,  'prob')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "[Back to top](#Index:) \n",
    "<a id='q6'></a>\n",
    "\n",
    "### Question 6: \n",
    "\n",
    "*20 points*\n",
    "\n",
    "Define a function `topic_frame` that takes, as inputs:\n",
    "  - headline (str): text of headline to determine topic inclusion\n",
    "  - model (sklearn estimator): fit estimator from sklearn.decomposition (LDA or NMF)\n",
    "  - vectorizer (sklearn transformer): fit vectorizer with vocabulary (CountVectorizer, TfidfVectorizer, or HashingVectorizer)\n",
    "  - n (int): number of tokens to include in the returned DataFrame. Default this value to 10.\n",
    "  \n",
    "Your function should return a DataFrame containing top n words relating to input headline topics using input model.\n",
    "    \n",
    "Consider the example below:\n",
    "\n",
    "```python\n",
    "topic_frame('Putin', lda, cvect)\n",
    "```\n",
    "\n",
    "Example Output:    \n",
    "<table border=\"1\" class=\"dataframe\">  <thead>    <tr style=\"text-align: right;\">      <th></th>      <th>prob</th>      <th>features</th>    </tr>  </thead>  <tbody>    <tr>      <th>3391</th>      <td>34.284904</td>      <td>president</td>    </tr>    <tr>      <th>1486</th>      <td>34.272390</td>      <td>election</td>    </tr>    <tr>      <th>1488</th>      <td>25.862762</td>      <td>elections</td>    </tr>    <tr>      <th>978</th>      <td>22.230037</td>      <td>congressional</td>    </tr>    <tr>      <th>3693</th>      <td>22.128197</td>      <td>republican</td>    </tr>    <tr>      <th>728</th>      <td>21.695774</td>      <td>carolina</td>    </tr>    <tr>      <th>3013</th>      <td>20.821177</td>      <td>north</td>    </tr>    <tr>      <th>3726</th>      <td>17.187756</td>      <td>results</td>    </tr>    <tr>      <th>3962</th>      <td>15.357398</td>      <td>senate</td>    </tr>    <tr>      <th>4593</th>      <td>15.255583</td>      <td>trump</td>    </tr>  </tbody></table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### GRADED\n",
    "\n",
    "### YOUR SOLUTION HERE\n",
    "def topic_frame(headline, model, vectorizer, n=10):\n",
    "    return\n",
    "\n",
    "###\n",
    "### YOUR CODE HERE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "Question 06",
     "locked": true,
     "points": "10",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
