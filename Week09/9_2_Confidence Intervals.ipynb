{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confidence intervals and Hypothesis testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outline\n",
    "\n",
    "- Confidence intervals and z-scores\n",
    "- z-score vs t-score\n",
    "- Hypothesis testing, the t-test, and p-values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confidence Interval and z-scores\n",
    "\n",
    "A confidence interval is an interval that contains the unknown parameter (such as the population mean $\\mu$) with certain degree of confidence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](images/ci1.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given a “Standard Bell Curve Z” having mean 0 and standard deviation 1, a z–score is the value $z_r$ such that $P(– z_r ≤ Z ≤ z_r ) = r$. That is, there is probability r between the\n",
    "points – $z_r$ and + $z_r$.\n",
    "\n",
    "We would like to say that µ is about $x$ ± some margin of error. We can never be 100% sure if the unknown $\\mu$ will really be within our margin of error. But with larger sample sizes, we have a higher probability that $\\mu$ will be within our bounds."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can define the z-score as\n",
    "\n",
    "$$\n",
    "z_{score} = \\frac{x-\\mu}{\\sigma}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Under the normality assumption\n",
    "\n",
    "$$P\\Big( \\bar{X} - 1.96\\cdot\\frac{\\sigma}{\\sqrt{n}}\\ \\le \\mu \\le \\ \\bar{X} + 1.96\\cdot\\frac{\\sigma}{\\sqrt{n}} \\Big) = 0.95 $$\n",
    "\n",
    "defines a confidence interval of 95%. In general, by the CLT, for reasonably large sample size $n$, the above equation is still approximately true. \n",
    "\n",
    "Then we can say that for a 95% CI for $\\mu$ when $\\sigma$ is know in:\n",
    "\n",
    "$$\\Big( \\bar{X} - 1.96\\cdot\\frac{\\sigma}{\\sqrt{n}}\\ ,\\ \\bar{X} + 1.96\\cdot\\frac{\\sigma}{\\sqrt{n}} \\Big)$$  \n",
    "\n",
    "More generally, if we define $z_{\\alpha/2}$ as the value that cuts off an area of $\\alpha/2$ in the uppter tail of the standard normal distribution, we can define a $1-\\alpha$ confidence interval for the population mean $\\mu$ as:\n",
    "\n",
    "$$\\Big( \\bar{X} - Z_{\\alpha/2}\\cdot\\frac{\\sigma}{\\sqrt{n}}\\ ,\\ \\bar{X} + Z_{\\alpha/2}\\cdot\\frac{\\sigma}{\\sqrt{n}} \\Big)$$  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To calculate $Z_{\\alpha/2}$ for a 95% confidence interval we can use the \"`.interval()`\" function or the \"`.ppf()`\" function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(-1.959963984540054, 1.959963984540054)\n",
      "1.959963984540054\n",
      "-1.959963984540054\n"
     ]
    }
   ],
   "source": [
    "print(stats.norm.interval(.95))\n",
    "print(stats.norm.ppf( 1- ((1 - .95)/2)))\n",
    "print(stats.norm.ppf( (1 - .95)/2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We can calculate the CI interval like this "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = .95\n",
    "interval_end = 1-((1-alpha)/2)\n",
    "z_mult = stats.norm.ppf(interval_end)\n",
    "sd = 25\n",
    "x_bar = 135\n",
    "n = 56"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Conventional Calulation:\n",
      " (128.45221989235253, 141.54778010764747)\n"
     ]
    }
   ],
   "source": [
    "# Using our calculated values from above and python to create CI\n",
    "print(\"\\nConventional Calulation:\\n\",\n",
    "      (x_bar - z_mult*(sd/np.sqrt(n)),x_bar + z_mult*(sd/np.sqrt(n)) ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Calculation with .interval():\n",
      " (128.45221989235253, 141.54778010764747)\n"
     ]
    }
   ],
   "source": [
    "# Calculating CI using the .interval function\n",
    "print(\"\\nCalculation with .interval():\\n\",  # \"loc\" is the mean of the distribution, \"scale\" is the sd\n",
    "      stats.norm.interval(alpha = .95, loc = x_bar, scale= sd/ np.sqrt(n)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## z-score vs t-score\n",
    "\n",
    "Z-score ($Z_{\\alpha/2}$) is used for a normal distribution, and t-score ($t_{\\alpha/2,df}$) is used for a t-distribution. You should use z-score if you know the population variance $\\sigma^2$. If not, you use the t-score. Since the population variance $\\sigma^2$ is almost never known, you almost always use t-score to calculate the confidence interval. After all, the purpose of using the confidence interval is to mitigate the issue of Population vs. Samples when estimating population parameters ($\\sigma^2$) from samples. If you know the population parameters, you probably don't need the confidence interval in the first place."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The \"`stats`\" package has a library for the t distribution. That we saw in the last video.\n",
    "\n",
    "The \"`t`\" library functions similarly to the \"`norm`\" library, except that degrees of freedom must be specified. Remember, degrees of freedom (df) in these cases is $n - 1$. Thus 21 observations would yeild $df = 20$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Mean:   119.8125\n",
      "Observations (n):   16\n",
      "Sample sd:   6.606992034958117\n",
      "t-multiplier:   2.131449545559323\n",
      "\n",
      "Confidence Interval:   119.8125 +/- 3.5206\n"
     ]
    }
   ],
   "source": [
    "# Calulating a CI with the t-score\n",
    "\n",
    "observations = [121, 110, 126, 112, 129, 118, 126, 127, 126, 111, 127, 113, 126, 115, 114, 116]\n",
    "\n",
    "n = len(observations) # find \"n\" -- the number of observations\n",
    "x_bar = np.mean(observations) # find \"x_bar\"-- the sample mean\n",
    "sd = np.std(observations) # find the sample standard deviation\n",
    "alpha = .95\n",
    "t_mult = stats.t.interval(alpha, df = n-1)[1]\n",
    "\n",
    "print(\"Sample Mean:  \", x_bar)\n",
    "print(\"Observations (n):  \", n)\n",
    "print(\"Sample sd:  \", sd)\n",
    "print(\"t-multiplier:  \", t_mult)\n",
    "\n",
    "print(\"\\nConfidence Interval:  \", x_bar, \"+/-\", round(t_mult * (sd / np.sqrt(n)),4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(119.70372356909532, 119.92127643090468)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can also use the t.interval function\n",
    "\n",
    "stats.t.interval(1 - alpha, len(observations) - 1, loc=np.mean(observations), scale=stats.sem(observations))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hypothesis testing and the t-test. Also p-values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose we have a hypothesized or baseline value $p$ and obtain from our data a value $\\hat{p}$ that’s smaller than $p$. If we’re interested in reasoning about whether $\\hat p$ is “significantly” smaller\n",
    "than $p$, one way to quantify this would be to assume the true value were p and then compute the probability of getting a value smaller than or as small as the one we observed (we can do the same thing for the case where $\\hat{p}$ is larger). If this probability is “very low”, we might\n",
    "think the hypothesized value $p$ is incorrect. This is the **hypothesis testing** framework."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We begin with a null hypothesis, which we call $H_0$ (this is the hypothesis that the true proportion is in fact p) and an alternative hypothesis, which we call $H_1$ or ( the hypothesis that the true mean is significantly smaller than p)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have the two hypotheses, we’ll use the data to test which hypothesis we should believe. “Significance”\n",
    "is usually defined in terms of a probability threshold $\\alpha$, such that we deem a particular result significant if the probability of obtaining that result under the null distribution is less than $\\alpha$. A common value for $\\alpha$ is 0.05, corresponding to a 1/20 chance of error. Once we obtain a particular value and evaluate its probability under the null hypothesis, this probability is known as a **p-value.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Some important definitions\n",
    "\n",
    "- In a **one-tailed hypothesis test**, we choose one direction for our alternative hypothesis: we either hypothesize that the test statistic is “significantly big”, or that the test statistic is “significantly small”.\n",
    "- In a **two-tailed hypothesis test**, our alternative hypothesis encompasses both directions: we hypothesize that the test statistic is simply different from the predicted value.\n",
    "- A **false positive** or Type I error happens when the null hypothesis is true, but we reject it. Note that the probability of a Type I error is $\\alpha$.\n",
    "- A **false negative** or Type II error happens when the null hypothesis is false, but we fail to reject it.\n",
    "- The **statistical power** of a test is the probability of rejecting the null hypothesis when it’s false (or equivalently, 1 − (probability of type II error)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The t-test\n",
    "\n",
    "A t-test is a type of inferential statistic used to determine if there is a significant difference between the means of two groups, which may be related in certain features.\n",
    "\n",
    "A t-test looks at the t-statistic, the t-distribution values, and the degrees of freedom to determine the statistical significance. \n",
    "\n",
    "The t-test hypothesis for the difference in mean is as follow:\n",
    "\n",
    "$$\n",
    "H_0: \\mu_1 - \\mu_2 = 0 \\\\\n",
    "H_1: \\mu_1 - \\mu_2 \\neq 0\n",
    "$$\n",
    "\n",
    "Where the $\\mu_i$ are the means for each population."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One-sided T-Test\n",
    "\n",
    "The one-sided t-test will tell us whether means of the sample and the population are different. \n",
    "\n",
    "Let's use data for body temperature. We know that the standard temperauture for a normal male is 98.6 $^oF$. In this case we will test how likely it is that our sample mean is equal to the standard temperature. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# Read into the data called `bodytemp`\n",
    "body = pd.read_csv(\"data/bodytemp.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>temp</th>\n",
       "      <th>sex</th>\n",
       "      <th>bpm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>96.3</td>\n",
       "      <td>0</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>96.7</td>\n",
       "      <td>0</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>96.9</td>\n",
       "      <td>0</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>97.0</td>\n",
       "      <td>0</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>97.1</td>\n",
       "      <td>0</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   temp  sex  bpm\n",
       "0  96.3    0   70\n",
       "1  96.7    0   71\n",
       "2  96.9    0   74\n",
       "3  97.0    0   80\n",
       "4  97.1    0   73"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View our data\n",
    "# 0 means male and 1 means female\n",
    "body.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_1sampResult(statistic=-5.715757449318526, pvalue=3.083840317315035e-07)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import scipy.stats\n",
    "true_mu = 98.6\n",
    "\n",
    "scipy.stats.ttest_1samp(body[body.sex == 0][\"temp\"], true_mu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This p-value means that there is only a 0.00003084% chance we would see these results from purely random data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ttest_1sampResult(statistic=array([0.65136319, 0.48796345]), pvalue=array([0.51785543, 0.62775216]))\n"
     ]
    }
   ],
   "source": [
    "# Another example\n",
    "rvs = stats.norm.rvs(loc = 5, scale = 10, size = (50,2))\n",
    "print(stats.ttest_1samp(rvs,5.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Two-sided t-test\n",
    "\n",
    "The two-sided t-test tells us whether two data samples have different means. Here, we take the null hypothesis that both groups have equal means. We don’t need a known population parameter for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_indResult(statistic=-2.2854345381654984, pvalue=0.02393188312240236)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run a t-test for the null hypothesis that men and women have the same body temperature. \n",
    "scipy.stats.ttest_ind(body[body.sex == 0][\"temp\"], body[body.sex == 1][\"temp\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This p-value means that there is only a 2% chance we would see these results from purely random data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confidence intervals for difference in means"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's calculate the 95% confidence interval (with a Z-distribution) of the difference of the means of the collections stored in obs1 and obs2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs1 = [22.9 , 26.08, 25.04, 22.09, 24.28, 31.3 , 25.47, 24.17, 23.42,\n",
    "       25.64, 23.96, 23.94, 25.35, 20.92, 27.74, 25.93, 26.9 , 27.87,\n",
    "       22.43, 23.73, 29.25, 25.66, 23.6 , 26.77, 17.38, 26.26, 17.67,\n",
    "       24.04, 19.42, 27.41, 30.02, 25.22, 26.47, 24.47, 22.85, 20.07,\n",
    "       29.46, 23.61, 26.54, 25.37]\n",
    "\n",
    "obs2 = [26.37, 32.62, 22.13, 22.64, 32.33, 25.62, 18.69, 26.86, 17.87,\n",
    "       18.16, 26.37, 25.77, 22.57, 27.41, 17.2 , 22.61, 26.97, 28.78,\n",
    "       24.02, 25.41, 27.88, 28.99, 30.06, 30.23, 24.19, 17.06, 24.38,\n",
    "       24.13, 25.87, 31.58, 21.19, 32.07, 30.07, 24.23, 27.37]\n",
    "\n",
    "# Calculate Sample Means\n",
    "mean_x = np.mean(obs1)\n",
    "mean_y = np.mean(obs2)\n",
    "\n",
    "# Calculate Sample Standard Deviations\n",
    "sd_x = np.std(obs1)\n",
    "sd_y = np.std(obs2)\n",
    "\n",
    "# Count Sample Sizes\n",
    "n_x = len(obs1)\n",
    "n_y = len(obs2)\n",
    "\n",
    "# Set Confidence level\n",
    "alpha = .95\n",
    "\n",
    "\n",
    "# Calculate Observed Difference of means\n",
    "diff = mean_x - mean_y\n",
    "\n",
    "# Calculate Standard Error\n",
    "se = np.sqrt( (sd_x**2/n_x) + (sd_y**2/n_y))\n",
    "\n",
    "# Find z-multiplier\n",
    "z_mult = stats.norm.interval(alpha)[1]\n",
    "\n",
    "\n",
    "# Calculate Confidence Interval\n",
    "lower_T = diff - z_mult * se\n",
    "upper_T = diff + z_mult * se"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confidence Interval:  -2.351070474933965  ,  1.0460704749339655\n"
     ]
    }
   ],
   "source": [
    "print(\"Confidence Interval: \", lower_T, \" , \", upper_T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p-value:  0.4515\n"
     ]
    }
   ],
   "source": [
    "# To calculate the p-value we use the t-statistic\n",
    "test_stat = diff/ se\n",
    "\n",
    "# Find p-value\n",
    "print(\"p-value: \", round((2*(stats.norm.cdf(test_stat))),4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import random\n",
    "random.seed(5)\n",
    "def roll_two_dice(n_simulations):\n",
    "    count = 0\n",
    "    for sim in range(n_simulations):\n",
    "        d1 = random.randint(1,6)\n",
    "        d2 = random.randint(1,6)\n",
    "        total - d1+d2\n",
    "        count +=1\n",
    "    return count/n_simulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'total' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-43ca2c148239>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mroll_two_dice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-16-02411ee447ae>\u001b[0m in \u001b[0;36mroll_two_dice\u001b[0;34m(n_simulations)\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0md1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0md2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mtotal\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0md1\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0md2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0mcount\u001b[0m \u001b[0;34m+=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mn_simulations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'total' is not defined"
     ]
    }
   ],
   "source": [
    "roll_two_dice(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import gamma\n",
    "=1.99\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma.stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 3\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x = np.linspace(0, 100, 200)\n",
    "y = gamma.pdf(x, a = 5)\n",
    "plt.plot(x,y)\n",
    "plt.fill_between(x, y, where = x <5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Question 5\n",
    "\n",
    "Many things are based on a normal distributions\n",
    "heights\n",
    "\n",
    "t-distribution \n",
    "Flip count 0,1,2,3,4 times - \n",
    "\n",
    "0     1\n",
    "1    1  1\n",
    "2   1   2   1\n",
    "3  1  3  3  1\n",
    "4\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t dist\n",
    "from scipy.stats import t\n",
    "tdist = t(34)\n",
    "# then get x from -2 to 2 and dram the plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6\n",
    "tdist.cdf(.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 7\n",
    "tdist.pdf(-.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Which is discrete function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binomial distribution\n",
    "data.binom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import expon\n",
    "\n",
    "use rvs and the parameters\n",
    "you need the "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computer confidence intervals\n",
    "\n",
    "\n",
    "df.groupby().[column.agg(['mean','count','std'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confidence intervals by adding and subtracting the count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normal Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.binomial(1, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distribution_of_flips = np.random.binomial(1000, 0.5)/1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(distribution_of_flips)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic = sns.load_dataset('titanic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "survived = titanic.loc[titanic['survived']==1]['fare'].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "died = titanic.loc[titanic['survived']==0]['fare'].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(survived, hist=False)\n",
    "sns.distplot(died, hist=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.ttest_ind(survived, died)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# diff between smokers and non smokers average tip\n",
    "tips = sns.load_dataset('tips')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smoker = tips.loc[tips['smoker']=='Yes']['tip'].dropna()\n",
    "nonsmoker = tips.loc[tips['smoker']=='No']['tip'].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.ttest_ind(smoker, nonsmoker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "numpy.stats.zscore(95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scipy.stats.norm.interval(1-95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.ppf(.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scipy.stats.norm.interval(.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "observations = [10,15,14,9,8,11]\n",
    "\n",
    "n=len(observations)\n",
    "alpha=.95\n",
    "t=stats.t.interval(alpha, df=n-1)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
